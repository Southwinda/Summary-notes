# 08.02-08.08 回顾

## 《推荐系统实战》笔记

## 第1章 好的推荐系统

### 1.1 什么是推荐系统

- 和分类目录、搜索引擎一起，解决信息过载问题。
- 和搜索引擎互补，在用户没有明确需求的时候，帮助用户发现感兴趣的新内容。
- 推荐系统可以更好地发掘物品的长尾(long tail)。

### 1.2 应用场景

- 电子商务、电影和视频、音乐、社交网络、阅读、基于位置的服务、个性化邮件和广告。

### 1.3 推荐系统评测

- 推荐系统实验方法：离线实验、用户调查、在线实验（ABtest）

- 一个新的算法上线，需要完成上述3个实验

  - 离线实验证明它在很多离线指标上优于现有的算法
  - 通过用户调查确定它的满意度不低于现有的算法
  - 通过在线AB测试确定它在我们关心的指标上优于现有的算法

- 评测指标：

  1. 用户满意度：通过问卷或在线实验获得。可以通过点击率、用户停留时间和转化率来衡量用户的满意度。

  2. 预测准确度：（最重要的离线指标）

     - 评分预测：预测用户对一个物品的评分，通过均方根误差（RMSE）和平均绝对误差（MAE）计算。
       $$
       \text{RMSE} = \sqrt{\frac{\sum_{u,i\in T}(r_{ui}-\hat r_{ui})^2}{|T|}} 
       $$

       $$
       \text{MAE}=\frac{\sum_{u,i\in T}|r_{ui}-\hat r_{ui}|}{|T|}
       $$

       RMSE加大了对于预测不准确物品的惩罚，评测更加苛刻。如果评分系统是整数，那么对于结果取整会见底MAE。

     - TopN推荐：给用户一个个性化推荐列表。通过precision和recall度量。
       $$
       \begin{align}
       \operatorname{Recall}&=\frac{\sum_{u \in U}|R(u) \cap T(u)|}{\sum_{u \in U}|T(u)|} \\
       \text { Precision }&=\frac{\sum_{u \in U}|R(u) \cap T(u)|}{\sum_{u \in U}|R(u)|}
       \end{align}
       $$
       选取不同的推荐列表长度*N*，计算出一组准确率/召回率，然后画出准确率/召回率曲线(precision/recall curve)。

     - TopN更适合应用需求，因为用户看完某一个物品之后，可能会打高分，但是实际上，用户可能不会看。（预测是否会看，比预测看完之后的评分更重要） 

  3. 覆盖率：推荐出来的物品占总物品集合的比例（发掘长尾的能力）
     $$
     \text { Coverage }=\frac{\left|\bigcup_{u \in \mathrm{U}} R(u)\right|}{|I|}
     $$
     其他的指标，信息熵和基尼系数
     $$
     H=-\sum_{i=1}^{n} p(i) \log p(i)\\
     G=\frac{1}{n-1} \sum_{j=1}^{n}(2 j-n-1) p\left(i_{j}\right)
     $$
     通过基尼系数，可以判断推荐系统是否具有马太效应（实际上是有的）。

  4. 多样性：满足用户广泛的兴趣，描述推荐列表中物品两两之间的不相似度。
     $$
     \text{Diversity} =1-\frac{\sum_{i, j \in R(u), i \neq j} s(i, j)}{\frac{1}{2}|R(u)|(|R(u)|-1)} 
     $$
     其中，相似性函数 $s(i,j)$ 可以使用不同，如内容相似性函数、协同过滤相似性函数。

  5. 新颖性：推荐用户没听说过的商品。

     - 最简单的方法：利用推荐结果的平均流行度，越不热门的物品越容易让用户觉得新颖。
     - 通过牺牲精度来提高多样性和新颖性很容易，难的是在不牺牲精度的情况下提高多样性和新颖度。

  6. 惊喜度：推荐结果和用户的历史兴趣不相似，但是，用户很满意。

  7. 信任度：用户信任推荐系统，就会增加和推荐系统的互动。

     - 提高信任度的方法：1. 增加透明度，2. 考虑用户的社交网络

  8. 实时性：

     - 用户有行为之后，推荐列表变化的速率来评测。
     - 新加入系统的物品，是否可以推荐给用户（冷启动问题）。

  9. 健壮性

     - 常见攻击手段：同时购买两件商品、恶意刷评论。
     - 测评方法：首先给定数据和算法，测试性能；然后模拟攻击加入噪声，再进行性能的测试。
     - 设计系统时，尽量采用代价高的用户行为。
     - 在使用数据之前，进行攻击检测，进行数据的清理工作。

  

## 第2章 利用用户数据

### 2.1 用户数据简介

- 用户行为推荐系统中，分为两种：显性反馈行为和隐性反馈行为
- 本章使用的数据是：无上下文信息的隐性反馈数据。

### 2.2 用户行为分析

- 互联网上很多数据分布都满足Power Law的分布，也称为长尾分布。
- 物品的流行度：对物品产生过行为的用户总数。
- 用户的活跃度：用户产生过行为的物品总数。
- 新用户倾向于热门的物品，老用户会逐渐开始浏览冷门物品。
- 仅仅基于用户行为数据设计的推荐算法称为协同过滤算法，协同过滤算法又可以分为：基于邻域的方法、隐语义模型、基于图的随机游走算法。

### 2.3 实验设计和算法测评

- 数据集：由GroupLens提供的MovieLens数据集。
- 实验设计：离线的M折交叉验证，研究基于隐性反馈数据的TopN推荐问题。
- 评价指标：precision、recall、coverage、新颖度（平均流行度）

### 2.4 基于邻域的算法

#### 2.4.1 User CF 

- User CF的两个步骤：

  1. 找到和目标用户兴趣相似的用户集合； 
  2. 找到这个集合中用户喜欢的，但是目标用户没听过的物品推荐给用户

- 两个用户相似度的度量（余弦相似度）：
  $$
  w_{uv} = \frac{|N(u) \bigcap N(v)|}{\sqrt{|N(u)||N(v)|}}
  $$
  其中，$N(u)$  表示用户 $u$ 有过正反馈的物品集合。

- 用户 $u$ 对于物品 $i$ 的感兴趣程度为：
  $$
  p(u,i)=\sum_{v\in S(u,K) \bigcap N(i)} w_{uv}r_{vi} 
  $$
  其中， $S(u,K)$ 是和用户 $u$ 兴趣最相近的 $K$ 个用户，$N(i)$ 是对物品 $i$ 有过行为的用户集合， $r_{vi}$ 是用户 $v$ 对物品 $i$ 的兴趣，此处有 $r_{vi}=1$。

- 从实验结果来看：

  - $K$ 越大，参考的人越多，结果越接近热门商品，流行度越高，覆盖率就越低。 

- 用户相似度的改进（User-IIF）
  $$
  w_{uv} = \frac{ \sum_{i\in |N(u) \bigcap N(v)|}  \frac1{\log(1+|N(i)|)} }{\sqrt{|N(u)||N(v)|}}
  $$
  和User CF相比，惩罚了热门的物品。

- User-IIF 在各项离线指标的性能上都略优于 User CF。

#### 2.4.2 Item CF 

- 物品相似度
  $$
  w_{ij}=\frac{|N(i) \bigcap N(j)|}{\sqrt{|N(i)||N(j)|}}
  $$
  其中， $N(i)$ 表示对物品 $i$ 有过行为的用户集合。潜在的逻辑是：如果两个物品共同出现在很多用户的兴趣中，则它们具有很大的相似度。

- 用户 $u$ 对于物品 $j$ 的感兴趣程度为：
  $$
  p(u,j)=\sum_{i\in N(u)\bigcap S(j,K) } w_{ji}r_{ui}
  $$
  其中，$N(u)$ 是用户喜欢的物品的集合，$S(j,K)$ 是和物品 $j$ 最相似的 $K$ 个物品的集合，$w_{ji}$ 是物品 $j$ 和 $i$ 的相似度，$r_{ui}$ 是用户 $u$ 对物品 $i$ 的兴趣。(对于隐反贵数据集，如果用户 $u$ 对物品 $i$ 有过行为，即可令 $r_{ui}=1$ )。

- 物品相似度的改进（IUF - Inverse User Frequence） 
  $$
  w_{i j}=\frac{\sum_{u \in N(i) \cap N(j)} \frac{1}{\log 1+|N(u)|}}{\sqrt{|N(i)||N(j)|}}
  $$
  惩罚了活跃度过高的用户。

- Item CF - IUF相比于Item CF，precision和recall比较接近，但是提高了覆盖率，降低了流行度。

- 相似度归一化可以提高推荐的准确度，也可以提高覆盖率和多样性。（各项离线指标都有提升）
  $$
  w_{i j}^{\prime}=\frac{w_{i j}}{\max _{j} w_{i j}}
  $$

- 哈利波特问题

  - 亚马逊上，任何购买一本书的人，几乎都会购买《哈利波特》。原因：《哈利波特》太热门了！！

  - 在公式
    $$
    w_{ij}=\frac{|N(i) \bigcap N(j)|}{\sqrt{|N(i)||N(j)|}}
    $$
    中，如果 $j$ 非常热门，那么分子就会越来越接近 $|N(i)|$ ，导致热门的 $j$ 会和很多物品都相似。

  - 改进办法：
    $$
    w_{i j}=\frac{|N(i) \cap N(j)|}{|N(i)|^{1-\alpha}|N(j)|^{\alpha}}
    $$
    其中，$\alpha \in [0.5, 1]$ ，可以惩罚热门的物品 $j$ 。当 $\alpha=0.5$ 时，就是普通的ItemCF。$\alpha$ 越大覆盖率越高，平均热门度也越低。通过这种方法，可以在适当牺牲准确率和召回率的情况下，显著提升覆盖率和新颖性。

#### 2.4.3 UserCF vs Item CF

- UserCF 推荐更加社会化，反映了用户所在小群体中物品的热门程度。

- ItemCF推荐更加个性化，反映了用户兴趣的传承。

- 综合对比：

  |          | UserCF                                                       | ItemCF                                                   |
  | -------- | ------------------------------------------------------------ | -------------------------------------------------------- |
  | 性能     | 适合用户少的场景                                             | 适用于物品数明显小于用户的场合                           |
  | 领域     | 时效性强，个性化兴趣不太明显的领域（如新闻）                 | 长尾物品丰富，个性化需求强烈的领域                       |
  | 实时性   | 用户的新行为，不一定导致推荐结果立即变化                     | 用户的新行为一定会导致结果实时变化                       |
  | 可解释性 | 可解释性差                                                   | 可解释性强                                               |
  | 冷启动   | 新物品上线后，只要有用户对它有行为，就可以推给类似的其他用户 | 没办法在不离线更新物品相似度的情况下，将新物品推荐给用户 |

- 两种算法经过优化之后，在离线性能上是近似的。

### 2.5 隐语义模型

- 推荐的另一种思路：对于物品和用户都按照兴趣进行分类，然后对于每个用户，在其喜欢的分类中进行推荐。

- LFM（latent factor model）通过如下公式计算用户 $u$ 对物品 $i$ 的兴趣：
  $$
  p(u,i) =r_{ui}=p^T_uq_i=\sum_{k=1}^K p_{u,k}q_{k,i} 
  $$
  这个公式中 $p_{u, k}$ 和 $q_{k, i}$ 是模型的参数，其中 $p_{u, k}$ 度量了用户 $u$ 的兴趣和第 $k$ 个隐类的关系，而 $q_{k, i}$ 度量了第 $k$ 个隐类和物品 $i$ 之间的关系。

- LFM在显性反馈数据上解决评分预测问题有很好的精度。针对隐性反馈数据，需要通过负采样构造负样本。

- 负采样的原则：

  - 对于每个用户，保证正负样本的平衡（数目相似）
  - 负采样时，要选取那些热门，但是用户没有行为的物品，这些物品更加代表用不不感兴趣。

- 采样之后，得到一个用户-物品集 $K=\{(u, i)\},$ 其中如果 $(u, i)$ 是正样本，则有 $r_{u i}=1,$ 否则有 $r_{u i}=0$ 。然后需要优化如下的损失函数来找到最合适的参数 $p$ 和 $q$ :
  $$
  C=\sum_{(u, i) \in K}\left(r_{u i}-\hat{r}_{u i}\right)^{2}=\sum_{(u, i) \in K}\left(r_{u i}-\sum_{k=1}^{K} p_{u, k} q_{k, i}\right)^{2}+\lambda\left\|p_{u}\right\|^{2}+\lambda\left\|q_{i}\right\|^{2}
  $$
  然后使用梯度下降法进行求解。

- 正负样本的比例ratio对于算法发掘长尾的能力有很大影响。

- 当数据稀疏时，LFM的性能会明显下降。

- LFM不能根据用户的行为变化实时调整推荐结果，冷启动问题也很明显。

- 和基于邻域的方法的对比

  |                    | 基于邻域的方法                                               | LFM                                                      |
  | ------------------ | ------------------------------------------------------------ | -------------------------------------------------------- |
  | 理论基础           | 基于统计的方法                                               | 基于学习的方法                                           |
  | 离线计算空间复杂度 | 需要很大内存，物品相关表（O(N^2)），用户相关表（O(N^2)）。在Netflix 比赛中需30GB内存。 | 空间复杂度低，O(F*(M+N)) ，在Netflix 比赛中只需4GB内存。 |
  | 时间复杂度         | 相差不大                                                     | 相差不大                                                 |
  | 实时推荐           | ItemCF可以实现实时推荐                                       | 无法实时推荐                                             |
  | 推荐解释           | ItemCF有较好的可解释性                                       | 难以解释                                                 |

  

### 2.6 基于图的模型

- 用户物品二分图

  <img src="pics/bipartite_user_item.jpg" alt="bipartite_user_item" style="zoom:80%;" />

- 影响两个顶点的相关性的因素：
  - 两个顶点之间的路径数
  - 两个顶点之间路径的长度
  - 两个顶点之间的路径经过的顶点
- 相关性高的顶点具有的特点：
  - 两个顶点之间有很多的路径相连
  - 链接两个顶点之间的路径长度都比较短
  - 路径不会经过出度比较大的顶点（惩罚热度高的节点）
- 基于以上因素，给出了PersonalRank算法，但算法的时间复杂度比较高。















## Recommender System

- offline 的基本技能
  1. python + 数据分析（pandas, seaborn, SQL） 
  2. 大数据（HDFS, spark, Dataframe, SQL） 
  3. ML/DL 
- 



# Plan of next week

- 


