# 复习大纲

### 1、算法与机器学习基础

- 重点
  - [ ] LR、决策树、随机森林、XGBoost
  - [x] 梯度下降法、随机梯度下降法、牛顿法
  - [ ] L0、L1、L2、L-Infinity Norm
  - [ ] Grid search、Bayesian Optimization 
  - [ ] 凸函数、凸集、Duality、KKT条件
  - [ ] Linear SVM、Dual of SVM
  - [ ] Kernel Trick、Mercer's Theorem
- 了解 
  - [ ] Projected Grid Descent

### 2、语言模型和序列标注

- 重点
  - [ ] 文本预处理（tfidf，stemming） 
  - [ ] 文本领域的特征工程
  - [x] N-gram，词向量模型
  - [ ] Latent Variable Models
  - [x] EM 算法和Local Optimality 
  - [ ] EM 与K-means、GMM
  - [ ] Variational Autoencoder 与 Text disentangling
  - [x] 有向图与无向图模型
  - [x] HMM模型以及参数估计
  - [x] Viterbi、Baum Welch
  - [x] CRF 与Linear Chain CRF
  - [x] CRF的Viterbi Decoding 与参数估计
- 了解
  - [ ] 倒排表、信息检索技术
  - [ ] 常见的smoothing techniques

### 3、信息抽取、词向量与知识图谱

- 重点
  - [ ] 命名实体识别技术
  - [ ] 信息抽取技术
  - [x] 词向量、Skip-Gram、Negative Sampling
  - [x] 矩阵分解、CBOW、Glove
  - [x] Contexualized Embedding 和 ELMo
  - [ ] KL Divergence 和 Gaussian Embedding
- 了解
  - [ ] 实体统一、实体消岐、指代消解
  - [ ] 知识图谱、实体与关系
  - [ ] 知识图谱嵌入技术
  - [ ] TransE、NTN详解
  - [ ] Node2Vec

### 4、深度学习与NLP

- 重点
  - [ ] Pytorch、Tensorflow详解
  - [ ] 表示学习、分布式表示技术
  - [x] 深度神经网络与BP算法详解
  - [x] RNN与Vanishing/ Exploding Gradient
  - [x] LSTM与GRU
  - [ ] Seq2seq 与注意力机制
  - [ ] Greedy Decoding与Beam search
  - [x] Bi-LSTM-CRF 模型
  - [ ] Self-attention，Transformer以及Transformer-XL
  - [ ] BERT详解
  - [ ] BERT-BiLSTM-CRF
  - [ ] GPT，MASS，XLNet
  - [ ] Low-resource learning
- 了解
  - [ ] 文本领域中的disentangling 
  - [ ] Neural Turing Machine
  - [ ] Memory Network 
  - [ ] 深度学习可视化

### 5、贝叶斯模型与NLP

- 了解

  - [ ] 概率图模型与条件独立
  - [ ] 主题模型
  - [ ] MCMC与吉布斯采样
  - [ ] Dynamic Topic Model
  - [ ] Supervised Topic Model 

  





















