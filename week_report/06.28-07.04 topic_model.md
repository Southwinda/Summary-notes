# 06.28-07.04 回顾

## 一. 概率分布复习

### 1 伯努利分布(*Bernoulli distribution*)

- 又称为**两点分布**或者**0-1分布**。 表示的是只有**两种**可能结果的**单次**随机试验。

- 服从伯努利分布的随机变量 $X$ ，记为 $X∼Ber(p)$ ，概率质量函数（probability mass function）为：
  $$
  f(k; p)=P(X=k)=\left\{\begin{array}{ll}p & \text { if } k=1 \\ q=1-p & \text { if } k=0\end{array}\right.
  $$
也可以写为：
  $$
  f(k; p)=P(X=k)=p^{k}(1-p)^{1-k}, k=0,1
  $$
  

### 2 二项分布(*Binomial distribution*)

- 将伯努利实验独立地重复**n次**，正例发生次数的概率分布。

- 服从二项分布的随机变量 $X$ ，记为 $X∼B(n,p)$ ，概率质量函数（probability mass function）为：
  $$
  f(k;n,p)=P(X=k)=C_{n}^{k} p^{k}(1-p)^{n-k}
  $$
  其中，$C_{n}^{k}=\frac{n !}{k !(n-k) !}$ 为二项系数。

- 从定义可知，伯努利分布是二项分布在 $n=1$ 时的特例。 典型例子是抛硬币。

- numpy代码

  ```python
  import numpy
  a = numpy.random.binomial(n=10, p=0.7, size = 1)
  ```

  

### 3 多项分布(*Multinomial Distribution*)

- 多项分布是二项分布的扩展，在单次实验中，可能有m种情况，这m种情况互斥且和为1。则发生其中一个结果的概率就是多项分布。

- 服从多项分布的随机变量 $X$ ，概率质量函数（probability mass function）为：
  $$
  \begin{aligned}
  f\left(x_{1}, \ldots, x_{k} ; n, p_{1}, \ldots, p_{k}\right) &=\operatorname{P}\left(X_{1}=x_{1} \text { and } \ldots \text { and } X_{k}=x_{k}\right) \\
  &=\left\{\begin{array}{cc}
  \frac{n !}{x_{1} ! \cdots x_{k} !} p_{1}^{x_{1}} \times \cdots \times p_{k}^{x_{k}}, & \text { when } \sum_{i=1}^{k} x_{i}=n \\
  \\
  0 & \text { otherwise }
  \end{array}\right.
  \end{aligned}
  $$

- 二项分布是多项分布在 $m=2$ 时的特例，典型例子是掷骰子。

- numpy代码

  ```python
  import numpy
  a = numpy.random.multinomial(n=10, pvals=[0.2,0.4,0.4], size = 1)
  ```



### 4 Beta分布(*Beta distribution*)

- **先验概率**：事情尚未发生，对于概率的预估。通过历史资料计算的先验概率称为**客观先验概率**，凭主观经验的先验概率，称为**主观先验概率**。

- **后验概率**：通过调查或者数据，增加新的附加信息，利用贝叶斯公式对先验概率进行修正，而后得到的概率。

- **似然函数**：给定参数，对数据出现的概率的描述。

- 先验概率和后验概率的**区别**：先验概率不是根据全部资料测定的，只是利用现有的材料计算的。后验概率使用了更多的信息，既有先验概率，也有补充资料。

- 先验概率和后验概率的**关系**：$posterior=likelihood \times prior$ 
  $$
  \begin{align}
  MLE:&\ \arg\max _{\theta} P(X|\theta) \\
  MAP:&\ \arg\max_{\theta} P(\theta|X)=\arg\max_{\theta}P(X|\theta)P(\theta)
  \end{align}
  $$

- Beta分布可以看作一个概率的概率分布（可以当成先验），概率密度函数（Probability density function）为：
  $$
  {\displaystyle {\begin{aligned}f(x;\alpha ,\beta )&=\mathrm {constant} \cdot x^{\alpha -1}(1-x)^{\beta -1}\\[3pt]&={\frac {x^{\alpha -1}(1-x)^{\beta -1}}{\displaystyle \int _{0}^{1}u^{\alpha -1}(1-u)^{\beta -1}\,du}}\\[6pt]&={\frac {\Gamma (\alpha +\beta )}{\Gamma (\alpha )\Gamma (\beta )}}\,x^{\alpha -1}(1-x)^{\beta -1}\\[6pt]&={\frac {1}{\mathrm {B} (\alpha ,\beta )}}x^{\alpha -1}(1-x)^{\beta -1}\end{aligned}}}
  $$
  where $Γ(z)$ is the [gamma function](https://en.wikipedia.org/wiki/Gamma_function). For any positive integer $n$, $\Gamma (n)=(n-1)!$ . The [beta function](https://en.wikipedia.org/wiki/Beta_function), ${\displaystyle \mathrm {B} }$, is a [normalization constant](https://en.wikipedia.org/wiki/Normalization_constant) to ensure that the total probability is 1.  

- **共轭分布**：后验概率分布函数和先验概率分布函数具有**相同形式**。共轭先验就是先验分布是beta分布，而后验分布同样是beta分布。

  - 二项分布的似然函数：
    $$
    P(X|\theta)\propto \theta^k(1-\theta)^{n-k}
    $$

  - Beta相当于先验：
    $$
    \operatorname{Beta}(a, b)=\frac{\theta^{a-1}(1-\theta)^{b-1}}{B(a, b)} \propto \theta^{a-1}(1-\theta)^{b-1}
    $$

  - 后验概率为：
    $$
    P(\theta|X)\propto \theta^k(1-\theta)^{n-k} * \theta^{a-1}(1-\theta)^{b-1} \\
    \propto\theta^{a+k-1}(1-\theta)^{b+n-k-1}
    $$
    令$a^\prime=a+k,b^\prime=b+n-k$ ，则后验概率服从 $Beta(a^\prime,b^\prime)$ 。

- 参考资料

  - 如何通俗理解 beta 分布？ - 小杰的回答 - 知乎 https://www.zhihu.com/question/30269898/answer/123261564
  
  - 伯努利分布、二项分布、多项分布、Beta分布、Dirichlet分布  https://blog.csdn.net/Michael_R_Chang/article/details/39188321

### 5 狄利克雷分布(*Dirichlet distribution*)

- 多项分布的共轭分布。概率密度函数（Probability density function）为：
  $$
  f\left(x_{1}, \ldots, x_{K} ; \alpha_{1}, \ldots, \alpha_{K}\right)=\frac{1}{\mathrm{B}(\alpha)} \prod_{i=1}^{K} x_{i}^{\alpha_{i}-1}
  $$
  其中：
  $$
  \mathrm{B}(\alpha)=\frac{\prod_{i=1}^{K} \Gamma\left(\alpha_{i}\right)}{\Gamma\left(\sum_{i=1}^{K} \alpha_{i}\right)}, \quad \alpha=\left(\alpha_{1}, \ldots, \alpha_{K}\right)
  $$

- 对 Dirichlet 分布做采样，就可以得到多项分布。对 Beta 分布做采样，就可以得到二项分布。
- 多项分布中，底数是分布参数，指数是随机变量；Dirichlet分布中，底数是随机变量，指数是分布参数。
- 参考资料
  
  - LDA中，多项式分布， 和狄利克雷分布的 形式一致，所以称为共轭，但是这两个分布的区别是什么呢？ - poodar.chu的回答 - 知乎 https://www.zhihu.com/question/39004744/answer/397828994





## 二、模型估计的方式

- 常见的模型估计方法可以分为**两个学派**（频率学派，贝叶斯学派）和**三种方法**（MLE、MAP、Bayesian）。

### 频率学派 vs 贝叶斯学派

- 频率学派：所有的数据是由参数空间中的**某一个**参数 $\theta^*$ 生成的。因此要求出此最优的参数，从而进行预测。

- 贝叶斯学派：参数空间的**每一个**参数 $\theta$ 都可能是生成数据的值，只不过是每个参数的概率不同，即参数也服从某个先验分布。

- 不同方法的对比：
  $$
  \begin{array}{c|c}
  \hline
  & \text {Approaches}&\text{Parameter Estimation} & \text{Inference}\\
  \hline \text{MLE}& \text{Frequentist} &\theta^*= \arg\max P(D|\theta)& x^\prime\rightarrow p(y^\prime|x^\prime,\theta^*) \\ 
  \hline \text{MAP}& \text{Frequentist} &\theta^*= \arg\max P(\theta|D)& x^\prime\rightarrow p(y^\prime|x^\prime,\theta^*) \\
  \hline \text{Bayesian}&\text{Bayesian} && x^\prime\rightarrow \int_\theta p(y^\prime|x^\prime,\theta) p(\theta|D)d\theta
  \\
  \hline
  \end{array}
  $$

- 贝叶斯方法中，会对每个参数 $\theta$ 计算其概率，但是这是很难计算的，因此需要使用抽样的方法。
- 从概率的角度看，贝叶斯学派的想法其实更为自然，这也是为什么贝叶斯学派的产生远早于频率学派（2014年是贝叶斯250周年）。但是贝叶斯方法本身有很多问题，比如当先验选的不好或者模型不好的时候你后验分布的具体形式可能都写不出来，跟别说做统计推断了。在当年电子计算机还没发展出来的时候，对这些情况做分析几乎是不可能的，这也就大大限制了贝叶斯方法的发展。而频率学派主要使用最优化的方法，在很多时候处理起来要方便很多。所以在频率学派产生后就快速地占领了整个统计领域。直到上世纪90年代依靠电子计算机的迅速发展，以及抽样算法的进步（Metropolis-hastings, Gibbs sampling）使得对于任何模型任何先验分布都可以有效地求出后验分布，贝叶斯学派才重新回到人们的视线当中。
- 就现在而言，贝叶斯学派日益受到重视当然是有诸多原因的，所以这并不意味这频率学派就不好或者不对。两个学派除了在参数空间的认知上有区别以外，方法论上都是互相借鉴也可以相互转化的。

### Bayesian Inference

- 为了计算 $\int_\theta p(y^\prime|x^\prime,\theta) p(\theta|D)d\theta$ ，要计算出 $p(\theta|D)$ 

  - Exact Inference
    $$
    p(\theta|D) = \frac{p(D|\theta)p(\theta)}{p(D)} = \frac{p(D|\theta)\,p(\theta)}{\int_{\theta}p(D,\theta) \, d\theta}= \frac{p(D|\theta)\,p(\theta)}{\int_{\theta_1}\int_{\theta_2}...\int_{\theta_\infin} p(D,\theta) \, d\theta} 
    $$ { }
    此处分母的 $p(D)$ 是不能省略的，因为省略之后，就不再是概率了。而分母的计算是很难的，一般难以计算，因此会采用采用的方法进行估计。

  - Approximate Inference
    $$
    \int_\theta p(y^\prime|x^\prime,\theta) p(\theta|D)d\theta \approx  \frac1S\sum_{s=1}^S  p(y^\prime|x^\prime,\theta^s) \\
    \theta^s \sim p(\theta|D)
    $$

  - 在采样时，如果每次都是随机采样（Monte Carlo），那么效率可能会比较低。而比较好的参数的周围存在其他好的参数的概率也比较大，这种性质叫做Locality。利用这样的性质，可以提高采到好的参数的概率，这样的**Monte Carlo + sequence**的方法，称为**Markov chain Monte Carlo（MCMC）**。 
  - 比较常见的抽样方法：
    - Metropolis-hastings
    - Gibbs sampling (*)
    - Rejection sampling
    - Langevin dynamics (*)


- Bayesian 考虑了无穷多的参数的可能性，可以看作模型集成，即使小数据集也不容易过拟合，在小数据集上效果优于神经网络。





### 参考资料 

- 贝叶斯学派与频率学派有何不同？ - Xiangyu Wang的回答 - 知乎 https://www.zhihu.com/question/20587681/answer/41436978















## Attention 补充

### 1. Soft vs Hard Attention

- **Soft attention**：将encoder的所有hidden state都进行attention的计算。
  - Pro：模型是可导的
  - Con：当输入序列很长时，计算量大
- **Hard attention**：是一个随机的过程，不会将encoder的所有输出都作为其输入，而是会依概率对输入端的hidden state进行采样，将采样后的部分hidden state进行计算。
  - Pro：计算量小
  - Con：模型不可导，需要更复杂的技术（variance reduction or reinforcement learning）来训练。

### 2. Global vs Local Attention

- **Global attention**：传统的attention，使用encoder的所有hidden state进行计算。
- **Local attention**：介于Soft Attention和Hard Attention之间的一种Attention。是可导的。先预测当前deocder端词，在source端对应的位置 $p_t$ ，然后基于该位置选择一个窗口，用于计算attention。
  - 当encoder句子不是很长时，相对Global Attention，计算量并没有明显减小。
  - 位置向量 $p_t$ 的预测并不非常准确，这就直接计算的到的local Attention的准确率。

<img src="pics/attention_global_local.png" alt="attention_global_local" style="zoom:50%;" />

### 3. 为什么自注意力模型（self-Attention model）在长距离序列中如此强大？

- 当使用神经网络来处理一个变长的向量序列时，我们通常可以使用CNN或RNN进行编码来得到一个相同长度的输出向量序列，无论CNN还是RNN其实都是对变长序列的一种“**局部编码**”：卷积神经网络显然是基于N-gram的局部编码；而对于循环神经网络，由于梯度消失等问题也只能建立短距离依赖。

- 如果要建立输入序列之间的长距离依赖关系，可以使用以下两种方法：一 种方法是增加网络的层数，通过一个深层网络来获取远距离的信息交互，另一种方法是使用全连接网络。
- 全连接网络虽然是一种非常直接的建模远距离依赖的模型， 但是无法处理变长的输入序列。不同的输入长度，其连接权重的大小也是不同的。这时我们就可以利用注意力机制来“动态”地生成不同连接的权重，这就是自注意力模型（self-attention model）。由于自注意力模型的权重是动态生成的，因此可以处理变长的信息序列。

### 4. Reference

- https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html
- [模型汇总24 - 深度学习中Attention Mechanism详细介绍：原理、分类及应用 - lqfarmer的文章 - 知乎](https://zhuanlan.zhihu.com/p/31547842) 
- [目前主流的attention方法都有哪些？ - JayLou娄杰的回答 - 知乎](https://www.zhihu.com/question/68482809/answer/597944559) 



## Loss in face recognition  

- 人脸识别的步骤：
  1. 找人脸
  2. 对齐人脸
  3. 识别

### 1. Softmax Loss

- softmax 函数
  $$
  \begin{align}
  \sigma(\mathbf{z})_{j}&=\frac{e^{z_{j}}}{\sum_{k=1}^{K} e^{z_{k}}} \\
  &=\frac{e^{z_{j}-z_{m a v}}}{\sum_{k=1}^{K} e^{z_{k}-z_{\max }}} \text { for } j=1, \ldots, K
  \end{align}
  $$
  将其剪去最大值，是为了避免溢出。

- softmax loss
  $$
  \begin{align}
  Softmax \ Loss&=\sum_{k=1}^{K}-y_{k} \log \left(\sigma_{k}\right) \\
  &=-y_{g t} \log \left(\sigma_{g t}\right)=-\log \left(\sigma_{g t}\right) \\
  &=CrossEntropy \ ( Softmax)
  \end{align}
  $$

### 2. SphereFace

- 从softmax开始：
  $$
  \begin{align}
  L&=-\log \left(\sigma_{g t}\right)=-\log \left(\frac{e^{z_{g t}}}{\sum_{k=1}^{K} e^{z_{k}}}\right) \\
  &=-\log \left(\frac{e^{W_{g t}^{T} x+b_{g t}}}{\sum_{k=1}^{K} e^{w_{k}^{T} x+b_{k}}}\right) \\
  &=-\log \left(\frac{e^{\| W_{g t} \| \|x\| \cos (\theta_{W_{gt}, x})+b_{g t}} }{\sum_{k=1}^{K} e^{\left\|W_{k}\right\|\| x \| \cos \left(\theta_{W_{k}, x}\right)+b_{k}}  }\right)
  \end{align}
  $$
  其中 $\theta_{i, j} \in(0, \pi)$ 代表两个向量 $i, j$ 之间的夹角，如果对 $W_{k}$ 归一化, 将偏置 $b$ 置为0, 即 $\left\|W_{k}\right\|=1$ and $b_{k}=0,$ 则有：
  $$
  L_{m}=-\log \left(\frac{e^{\|x\| \cos \left(\theta_{W t}, x\right)}}{\sum_{k=1}^{K} e^{\|x\| \cos \left(\theta_{W k}, x\right)}}\right)
  $$
  下标 m 表示 modified 。对于 $\theta$ 我们乘上一个大于等于1的整数 $m:$
  $$
  L_{a n g}=-\log \left(\frac{e^{\|x\| \cos \left(m \theta_{W t}\right)}}{\sum_{k=1}^{K} e^{\| x \mid \cos \left(m \theta_{W_{k}, x}\right)}}\right) m \in\{1,2, \ldots\}
  $$
  
  这样不仅放大了类之间的距离，也因放大了同类 $W_{g t}^{T}$ 与 $x$ 之间的间隔而使类内更聚拔。不过上述公式仍有问题：原来的 $\theta_{i, j} \in(0, \pi),$ 如今 $m \theta_{i, j} \in(0, m \pi)$ 超出了向量之间的夹角函数 $\operatorname{cos}$ 定义域范围$(0, \pi)$ 怎么办?那就变个函数，把n个cos怼起来变成一个递减的连续的函数：
  $$
  \psi\left(\theta_{i, j}\right)=(-1)^{n} \cos \left(m \theta_{i, j}\right)-2 n, \theta_{i, j} \in\left[\frac{n \pi}{m}, \frac{(n+1) \pi}{m}\right], n \in[0, m-1]
  $$
  这样一来：
  $$
  L_{a n g}=-\log \left(\frac{e^{\|x\| \psi\left(\theta_{W_{g t}, x}\right)}}{e^{\|x\| \psi\left(\theta_{W_{g t}, x}\right)}+\sum_{k \neq g t} e^{\|x\| \cos \left(\theta_{W_{k}, x}\right)}}\right)
  $$
  
  如此我们就得到了SphereFace的损失函数 A-Softmax

### 3. CosFace

- 和SphereFace类似，CosFace也是从 SoftMax 的余弦表达形式入手，令 $\left\|W_{k}\right\|=1$ and $b_{k}=0$ 。与此同时，作者发现 $\|x\|$ 对于分类并没有舍帮助，所以干脆将其固定 $\|x\|=s,$ 所以有：
  $$
  L_{n s}=\frac{1}{N} \sum_{i}-\log \frac{e^{s \cos \left(\theta_{y_{i}, i}\right)}}{\sum_{j} e^{s \cos \left(\theta_{j, i}\right)}}
  $$
  $n s$ 应该代表归一化的 $\operatorname{SoftMax~}$，接下来与上文 $A-S o f t M a x$ 类似的是也引入了常数 $m,$ 不同的是这里的 $m$ 是加上去的：
  $$
  L_{l m c}=\frac{1}{N} \sum_{i}-\log \frac{e^{s\left(\cos \left(\theta_{y_{i}, i}\right)-m\right)}}{e^{s\left(\cos \left(\theta_{y_{i}, i}\right)-m\right)}+\sum_{j \neq y_{i}} e^{s \cos \left(\theta_{j}, i\right)}}
  $$
  subject to:
  $$
  W=\frac{W^{*}}{\left\|W^{*}\right\|}\\
  x=\frac{x^{*}}{\left\|x^{*}\right\|} \\
  \cos \left(\theta_{j}, i\right)=W_{j}^{T} x_{i}
  $$
  
  以上我们就得到了cosFace中提出的 Large Margin Cosine Loss

### 4. ArcFace

- 和CosFace非常类似，只是将 $m$ 作为角度加上去了，这样就强行拉大了同类之间的角度，使得神经网络更努力地将同类收得更紧。
  $$
  L=-\frac{1}{N} \sum_{i=1}^{N} \log \frac{e^{s\left(\cos \left(\theta_{y_{i}}+m\right)\right)}}{e^{s\left(\cos \left(\theta_{y_{i}}+m\right)\right)}+\sum_{j=1, j \neq y_{i}}^{n} e^{s \cos \theta_{j}}}\\
  =-\frac{1}{N} \sum_{i}\log \frac{e^{s\left(\cos \left(\theta_{y_{i}, i}+m\right)\right)}}{e^{s\left(\cos \left(\theta_{y_{i}, i}+m\right)\right)}+\sum_{j \neq y_{i}} e^{s \cos \left(\theta_{j}, i\right)}}
  $$
  subject to:
  $$
  W=\frac{W^{*}}{\left\|W^{*}\right\|}\\
  x=\frac{x^{*}}{\left\|x^{*}\right\|}\\
  \cos \left(\theta_{j}, i\right)=W_{j}^{T} x_{i}
  $$
  
- 伪代码实现步骤

  1. 对 $x$ 进行归一化
  2. 对 $W$ 进行归一化
  3. 计算 $Wx$ 得到预测向量 $y$
  4. 从 $y$ 中挑出与ground truth对应的值
  5. 计算其反余弦得到角度
  6. 角度加上$m$
  7. 得到挑出从 $y$ 中挑出与ground truth对应的值所在位置的独热码
  8. 将 $\cos (\theta+m)$ 通过独热码放回原来的位置
  9. 对所有值乘上固定值 $s$ 
### 5. metric learning的class-level总结

- 上述几种loss都可以总结为metric learning中的class-level方法，都是在softmax的基础上进行的改进。可以总结为下表：
  $$
  \begin{array}{c|c}
    \hline \text { Loss Functions } & \text { Decision Boundaries } \\
    \hline \text { Softmax } & \left(W_{1}-W_{2}\right) x+b_{1}-b_{2}=0 \\
    \text { W-Norm Softmax } & \|x\|\left(\cos \theta_{1}-\cos \theta_{2}\right)=0 \\
    \text { SphereFace  } & \|x\|\left(\cos m \theta_{1}-\cos \theta_{2}\right)=0 \\
    \text { F-Norm SphereFace } & s\left(\cos m \theta_{1}-\cos \theta_{2}\right)=0 \\
    \text { CosineFace } & s\left(\cos \theta_{1}-m-\cos \theta_{2}\right)=0 \\
    \text { ArcFace } & s\left(\cos \left(\theta_{1}+m\right)-\cos {\theta}_{2}\right) =0 \\
    \hline
    \end{array}
  $$

### 6. metric learning的 pair-level 方法

- 除了上述的方法，还有一种方法就是使用siamese network，分别对不同的图片生成feature vector，然后使用triplet loss进行优化。思路和word2vec比较类似。

- 三元组（Triplet）计算而来的损失（Loss）由Anchor(A)，Negative(N)，Positive(P)组成，基点为A,正匹配为P，负匹配为N。

  <img src="pics/triplet_loss.jpg" alt="triplet_loss" style="zoom:120%;" />

- 损失函数：
  $$
  L(A,P,N)=\max(\|f(A)-f(P) \|^2- \|f(A)-f(N) \|^2 + \alpha,\ 0)
  $$

- P和N都是从样本中构造出来的pair，为了模型能够学到更多的东西，一般要选择更难学习的pair。例如满足以下条件：
  $$
  \|f(A)-f(P) \|^2\approx \|f(A)-f(N) \|^2
  $$
  或者，使用hard triplet，具体而言是选择hard positive和hard negative。
  $$
  \text{Hard positive:  }\  \arg\max _{x_i^p}\| f(x_i^a)-f(x_i^p) \|^2_2 \\
  \text{Hard negative:  }\  \arg\min _{x_i^n}\| f(x_i^a)-f(x_i^n) \|^2_2
  $$
  类比，airbnb那篇文章中，negative sampling的时候，选择一些更难分辨的负样本，从而学到更好的embedding。

- triplet loss 的三塔结构

  <img src="pics/triplet_loss_三塔结构.jpg" alt="triplet_loss_三塔结构" style="zoom:80%;" />

- pseudo-siamese network，伪孪生神经网络，两边可以是不同的神经网络（如一个是lstm，一个是cnn），也可以是相同类型的神经网络。
- 孪生神经网络用于处理两个输入**"比较类似"**的情况。伪孪生神经网络适用于处理两个输入**"有一定差别"**的情况。比如，我们要计算两个句子或者词汇的语义相似度，使用siamese network比较适合；如果验证标题与正文的描述是否一致（标题和正文长度差别很大），或者文字是否描述了一幅图片（一个是图片，一个是文字），就应该使用pseudo-siamese network。 

### 7. circle loss 

- 给定特征空间中的单个样本 $x$，假设与 $x$ 相关的类内相似度分数有 $K$ 个，与 $x$ 相关的类间相似度分数有 $L$ 个，分 别记为 $\left\{s_{p}^{i}\right\}\{i=1,2, \ldots, K\}$ 和 $\{s_{n}^{j}\}\{j=1,2, \ldots, L\}$ 。
  $$
  \begin{aligned}
  \mathcal{L}_{u n i} &=\log \left[1+\sum_{i=1}^{K} \sum_{j=1}^{L} \exp \left(\gamma\left(s_{n}^{j}-s_{p}^{i}+m\right)\right)\right] \\
  &=\log \left[1+\sum_{j=1}^{L} \exp \left(\gamma\left(s_{n}^{j}+m\right)\right) \sum_{i=1}^{K} \exp \left(\gamma\left(-s_{p}^{i}\right)\right)\right]
  \end{aligned}
  $$

- 上式可以转换为class-level的classification loss
  $$
  \begin{aligned}
  \mathcal{L}_{a m} &=\log \left[1+\sum_{j=1}^{N-1} \exp \left(\gamma\left(s_{n}^{j}+m\right)\right) \exp \left(-\gamma s_{p}\right)\right] \\
  &=-\log \frac{\exp \left(\gamma\left(s_{p}-m\right)\right)}{\exp \left(\gamma\left(s_{p}-m\right)\right)+\sum_{j=1}^{N-1} \exp \left(\gamma s_{n}^{j}\right)}
  \end{aligned}
  $$
  其中，$N$ 是类别的数量，$s_{n}^{j}=w_{j}^{\top} x /\left(\left\|w_{j}\right\|\|x\|\right)$ ，$w_j$ 是第 $j$ 个非类别的权重，$s_{p}=w_{y}^{\top} x /\left(\left\|w_{y}\right\|\|x\|\right)$ ，$w_y$ 是类别对应的权重。

- 也可以转化为pair-level的triplet loss
  $$
  \begin{aligned}
  \mathcal{L}_{t r i} &=\lim _{\gamma \rightarrow+\infty} \frac{1}{\gamma} \mathcal{L}_{u n i} \\
  &=\lim _{\gamma \rightarrow+\infty} \frac{1}{\gamma} \log \left[1+\sum_{i=1}^{K} \sum_{j=1}^{L} \exp \left(\gamma\left(s_{n}^{j}-s_{p}^{i}+m\right)\right)\right] \\
  &=\max \left[s_{n}^{j}-s_{p}^{i}+m\right]_{+}
  \end{aligned}
  $$
  其中，$s_{n}^{j}=\left(x_{n}^{j}\right)^{\top} x /\left(\left\|x_{n}^{j}\right\|\|x\|\right)$  ， $s_p^i=\left(x_{p}^{i}\right)^{\top} x /\left(\left\|x_{p}^{i}\right\|\|x\|\right)$  

-  Circle Loss
  $$
  \begin{aligned}
  \mathcal{L}_{\text {circle }} &=\log \left[1+\sum_{i=1}^{K} \sum_{j=1}^{L} \exp \left(\gamma\left(\alpha_{n}^{j} s_{n}^{j}-\alpha_{p}^{i} s_{p}^{i}\right)\right)\right] \\
  &=\log \left[1+\sum_{j=1}^{L} \exp \left(\gamma \alpha_{n}^{j} s_{n}^{j}\right) \sum_{i=1}^{K} \exp \left(-\gamma \alpha_{p}^{i} s_{p}^{i}\right)\right.
  \end{aligned}
  $$
  再定义 $s_p$ 的最优值为 $O_p$，$s_n$ 的最优值为 $O_n$；$O_n < O_p$。当一个相似性得分与最优值偏离较远，Circle Loss 将分配较大的权重，从而对它进行强烈的优化更新。为此，以自定步调（self-paced）的方式给出了如下定义：
  $$
  \left\{\begin{array}{c}
  \alpha_{p}^{i}=\left[O_{p}-s_{p}^{i}\right]_{+} \\
  \alpha_{n}^{j}=\left[s_{n}^{j}-O_{n}\right]_{+}
  \end{array}\right.
  $$

-  Circle Loss类内余量和类间余量 

  - 不同于优化 $(s_n - s_p)$ 的损失函数，在 Circle Loss 中，$s_n$ 和 $s_p$ 是不对称的，本文为其各自定义了余量 $∆_n$ 和 $∆_p$，这样可得到最终带余量的 Circle Loss：
    $$
    \mathcal{L}_{\text {circle}}=\log \left[1+\sum_{j=1}^{L} \exp \left(\gamma \alpha_{n}^{j}\left(s_{n}^{j}-\Delta_{n}\right)\right) \sum_{i=1}^{K} \exp \left(-\gamma \alpha_{p}^{i}\left(s_{p}^{i}-\Delta_{p}\right)\right)\right]
    $$

  - 通过推导决策边界，本文进一步分析 $∆_n$ 和 $∆_p$。为简单起见，这里以二元分类的情况进行说明，其中决策边界是在$a_{n}\left(s_{n}-\Delta_{n}\right)-a_{p}\left(s_{p}-\Delta_{p}\right)=0$ 处得到，再根据以上的两式，可以得到决策边界：
    $$
    \begin{array}{l}
    \left(s_{n}-\frac{O_{n}+\Delta_{n}}{2}\right)^{2}+\left(s_{p}-\frac{O_{p}+\Delta_{p}}{2}\right)^{2}=C \\
    \text{where }\  C=\left(\left(O_{n}-\Delta_{n}\right)^{2}+\left(O_{p}-\Delta_{p}\right)^{2}\right) / 4
    \end{array}
    $$

  - Circle Loss 有 5 个超参数，即 $O_p$、$O_n$、$γ$、$∆_n$ 和 $∆_p$。通过将 $O_p = 1+m, O_n =-m, ∆_p = 1-m, ∆_n = m$。可将上式约简为：
    $$
    \left(s_{n}-0\right)^{2}+\left(s_{p}-1\right)^{2}=2 m^{2}
    $$
    上式作为决策边界，可对 Circle Loss 进行另外一番解读。其目标是优化 $s_p → 1$ 和 $s_n → 0$。参数 $m$ 控制着决策边界的半径，并可被视为一个松弛因子。换句话说，Circle Loss 期望 $s_{p}^{i}>1-m $ 且 $s_{n}^{j}<m$ 。因此，超参数仅有 2 个，即扩展因子 $γ$ 和松弛因子 $m$。



### Reference

- 人脸识别损失函数简介与Pytorch实现：ArcFace、SphereFace、CosFace - Uno Whoiam的文章 - 知乎 https://zhuanlan.zhihu.com/p/60747096
- 人脸识别合集 | 10 ArcFace解析 - Mengcius的文章 - 知乎 https://zhuanlan.zhihu.com/p/76541084
- 通俗易懂-arcface - 神奇小双双的文章 - 知乎 https://zhuanlan.zhihu.com/p/101059838
- ArcFace: Additive Angular Margin Loss for Deep Face Recognition https://arxiv.org/pdf/1801.07698.pdf
- ArcFace的实现：https://github.com/deepinsight/insightface 
- Triplet Loss - 黄鑫的文章 - 知乎 https://zhuanlan.zhihu.com/p/40400141
- Siamese network 孪生神经网络--一个简单神奇的结构 - mountain blue的文章 - 知乎 https://zhuanlan.zhihu.com/p/35040994 
- 旷视研究院提出Circle Loss，革新深度特征学习范式 - 旷视科技的文章 - 知乎 https://zhuanlan.zhihu.com/p/117716663



# Plan of next week

- 


